{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8b4dac",
   "metadata": {},
   "source": [
    "### Image thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('uttam.jpg')\n",
    "\n",
    "thresh, output = cv.threshold(image, 100, 200, cv.THRESH_BINARY)\n",
    "cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Threshold Image\", output)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "319ff6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('uttam.jpg', 0)\n",
    "\n",
    "# output = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 111, 30)\n",
    "# output = cv.adaptiveThreshold(image, 100, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 111, 30)\n",
    "output = cv.adaptiveThreshold(image, 200, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11, 30)\n",
    "\n",
    "\n",
    "cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Threshold Image\", output)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da451cb",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59158762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('uttam.jpg', 0)\n",
    "\n",
    "blur_image = cv.GaussianBlur(image, (3,3), 200)\n",
    "\n",
    "canny_edges_original = cv.Canny(image, 100, 100)\n",
    "canny_edges_blur = cv.Canny(blur_image, 100, 100)\n",
    "\n",
    "# cv.imshow(\"Original Image\", image)\n",
    "# cv.imshow(\"Blur Image\", blur_image)\n",
    "cv.imshow(\"Edge Image Original\", canny_edges_original)\n",
    "cv.imshow(\"Edge Image Blur\", canny_edges_blur)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('uttam.jpg', 0)\n",
    "\n",
    "laplacian_edges = cv.Laplacian(image, cv.CV_64F, ksize=3)\n",
    "blur_image = cv.GaussianBlur(image, (3,3), 200)\n",
    "blured_laplacian_edges = cv.Laplacian(blur_image, cv.CV_64F, ksize=3)\n",
    "\n",
    "# cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Laplacian Image\", laplacian_edges)\n",
    "cv.imshow(\"Blured Laplacian Image\", laplacian_edges)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a766633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = cv.imread('uttam.jpg', 0)\n",
    "\n",
    "sobel_edges_x = cv.Sobel(image, cv.CV_64F, 1, 0, ksize=3)\n",
    "sobel_edges_y = cv.Sobel(image, cv.CV_64F, 0, 1, ksize=3)\n",
    "blur_image = cv.GaussianBlur(image, (3,3), 200)\n",
    "blured_laplacian_edges_x = cv.Sobel(blur_image, cv.CV_64F, 1, 0, ksize=3)\n",
    "sobel_combined = cv.magnitude(sobel_edges_x, sobel_edges_y)\n",
    "\n",
    "# cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Sobel Image X\", sobel_edges_x)\n",
    "cv.imshow(\"Sobel Image Y\", sobel_edges_y)\n",
    "cv.imshow(\"Sobel Image Combined\", np.uint8(sobel_combined))\n",
    "# cv.imshow(\"Blured Sobel Image\", blured_laplacian_edges_x)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052c952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = cv.imread('uttam.jpg', 0)\n",
    "\n",
    "\n",
    "scharr_x = cv.Scharr(image, cv.CV_64F, 1, 0)\n",
    "scharr_y = cv.Scharr(image, cv.CV_64F, 0, 1)\n",
    "scharr_combined = cv.magnitude(scharr_x, scharr_y)\n",
    "\n",
    "cv.imshow(\"Scharr Image X\", scharr_x)\n",
    "cv.imshow(\"Scharr Image Y\", scharr_y)\n",
    "cv.imshow(\"Scharr Image Combined\", np.uint8(scharr_combined))\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99416071",
   "metadata": {},
   "source": [
    "### Draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f819055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('uttam.jpg')\n",
    "original_image = cv.imread('uttam.jpg')\n",
    "\n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "# _, thresh = cv.threshold(gray_image, 100, 255, cv.THRESH_BINARY)\n",
    "# contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "edges = cv.Canny(image, 100, 200)\n",
    "contours, hierarchy = cv.findContours(edges, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "cv.drawContours(image, contours, -1, (0,0,255), 3)\n",
    "cv.imshow(\"Original Image\", original_image)\n",
    "cv.imshow(\"Contours Image\", image)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b76484",
   "metadata": {},
   "source": [
    "### Understanding and creating own image using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8fd432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058, 1180, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = cv.imread('uttam.jpg')\n",
    "print(image.shape)\n",
    "# print(f\"1st set {image[0]}\")\n",
    "# print(f\"2ed set {image[0][0]}\")\n",
    "# print(f\"3rd set {image[0][0][0]}\")\n",
    "\n",
    "cropped_image = image[200:600, 350:850]\n",
    "# image[:400, 400:] = 0 # Black Color\n",
    "# image[:400, 400:] = 255 # White Color\n",
    "cropped_image[0:, 0:] = [100, 0, 0] # BGR Image \n",
    "cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Cropped Image\", cropped_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "652814ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "\n",
    "image[:200, :200] = [255,0,0]\n",
    "image[200:, :200] = [0,255,0]\n",
    "image[:200, 200:] = [0,0,255]\n",
    "image[200:, 200:] = [200,160,100]\n",
    "image[400//3: 2 * 400 // 3, 400//3: 2 * 400 // 3] = [200,160,0]\n",
    "# image[200:300, 150:250] = 255\n",
    "center_y = image.shape[0] // 2\n",
    "center_y = image.shape[1] // 2\n",
    "radius = 40\n",
    "cv.circle(image, (center_y, center_y), radius, (255, 255, 255), -1)\n",
    "cv.imwrite(\"numpy_image.jpg\", image)\n",
    "\n",
    "cv.imshow(\"Numpy Image\" , image)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838035ca",
   "metadata": {},
   "source": [
    "### Color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = cv.imread('numpy_image.jpg')\n",
    "hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([100, 130, 50])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "lower_red = np.array([0, 140, 70])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "# lower_red = np.array([170, 140, 70])\n",
    "# upper_red = np.array([180, 255, 255])\n",
    "\n",
    "lower_green = np.array([35, 140, 70])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "\n",
    "lower_yellow = np.array([20, 140, 70])\n",
    "upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "# output = cv.inRange(hsv_image, lower_blue, upper_blue)\n",
    "# output = cv.inRange(hsv_image, lower_red, upper_red)\n",
    "\n",
    "blue = cv.inRange(hsv_image, lower_blue, upper_blue)\n",
    "red = cv.inRange(hsv_image, lower_red, upper_red)\n",
    "green = cv.inRange(hsv_image, lower_green, upper_green)\n",
    "yellow = cv.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "\n",
    "output = cv.bitwise_or(yellow, red, green)\n",
    "detected_color = cv.bitwise_and(image, image, mask=output)\n",
    "\n",
    "cv.imshow(\"Original Image\" , image)\n",
    "cv.imshow(\"HSV Image\" , hsv_image)\n",
    "cv.imshow(\"Detected Blue Color\" , detected_color)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b8dd4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "image = cv.imread('numpy_image.jpg')\n",
    "hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "color_dict = {\n",
    "    'red': ([0, 140, 70], [10, 255, 255]),\n",
    "    'blue': ([100, 130, 50], [140, 255, 255]),\n",
    "    'green': ([35, 140, 70], [85, 255, 255]),\n",
    "    'yellow': ([20, 140, 70], [30, 255, 255]),\n",
    "    'magenta': ([20, 140, 70], [30, 255, 255]),\n",
    "}\n",
    "\n",
    "for color_name, (lower, upper) in color_dict.items():\n",
    "    lower_color = np.array(lower)\n",
    "    upper_color = np.array(upper)\n",
    "    output = cv.inRange(hsv_image, lower_color, upper_color)\n",
    "    detected_color = cv.bitwise_and(image, image, mask=output)\n",
    "    cv.imshow(f\"Detected {color_name} Image\", detected_color)\n",
    "\n",
    "cv.imshow(\"Original Image\" , image)\n",
    "# cv.imshow(\"HSV Image\" , hsv_image)\n",
    "# cv.imshow(\"Detected Blue Color\" , detected_color)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
